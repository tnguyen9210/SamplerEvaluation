{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75acf400-9012-416f-ab8e-896be9d07f05",
   "metadata": {},
   "source": [
    "### Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffbaad4-45e5-460e-a579-487294cb45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_palette(\"tab10\")\n",
    "\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "rnd.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import bayes_logistic\n",
    "from pypolyagamma import PyPolyaGamma\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69222caf-f463-4b3c-a384-21f664dc3b14",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8787956b-f783-47dd-8800-78b6ebdb83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# data_x parameters\n",
    "num_data = 2\n",
    "num_data_half = num_data // 2\n",
    "num_feats = 2\n",
    "\n",
    "# num_samples \n",
    "num_samples = 1000\n",
    "\n",
    "# weights prior distribution parameters\n",
    "weights_prior_params = [[0.0, 0.0], [[50.0, 0.0], [0.0, 50.0]]]\n",
    "\n",
    "pg_burnin_steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be26f30d-e44b-47a7-bf7c-149d5e738292",
   "metadata": {},
   "source": [
    "### Generate data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ba1a55-593d-4b3a-9ad4-d75746d6e792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 0]]\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate data_x\n",
    "# data_x = stats.uniform.rvs(0, 1, size=(num_data, num_feats), random_state=12345)\n",
    "data_x = np.array([[0, 1], [1, 0]])\n",
    "print(data_x)\n",
    "print(data_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b768fe-fa72-4f5d-9bcf-90ed3c6350b8",
   "metadata": {},
   "source": [
    "### PolyaGamma Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c0bb52-6995-4493-89bb-f80981bece97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sample_polyagamma(\n",
    "    X, y, pg_dist, weights_prior_params, burnin_steps, num_samples_i):\n",
    "    #\n",
    "    num_data, num_feats = X.shape\n",
    "\n",
    "    # Gibbs sampling with PG augmentation for burnin_steps\n",
    "    # init params for gibb sampling are set to be the same as params of prior\n",
    "    beta_mu = np.array(weights_prior_params[0])\n",
    "    beta_cov = np.array(weights_prior_params[1])\n",
    "    beta_hat = np.random.multivariate_normal(beta_mu, beta_cov)\n",
    "    k = y - 1/2\n",
    "\n",
    "    # pg = PyPolyaGamma(seed=0)\n",
    "    # perform Gibbs sampling\n",
    "    for bid in range(burnin_steps+1):\n",
    "        # ω ~ PG(b, c) = PG(1, x*β).\n",
    "        omega_b = np.ones(num_data)\n",
    "        omega_c = X @ beta_hat\n",
    "        omega_diag = np.array(\n",
    "            [pg_dist.pgdraw(b, c) for b, c in zip(omega_b, omega_c)])\n",
    "\n",
    "        # β ~ N(m, V).\n",
    "        V = np.linalg.inv(X.T @ np.diag(omega_diag) @ X + np.linalg.inv(beta_cov))\n",
    "        m = np.dot(V, X.T @ k + np.linalg.inv(beta_cov) @ beta_mu)\n",
    "        beta_hat = np.random.multivariate_normal(m, V)\n",
    "        # print(m)\n",
    "    # stop\n",
    "    if num_samples_i == 0:\n",
    "        return beta_hat, _\n",
    "    \n",
    "    # samples\n",
    "    beta_hat_return = beta_hat\n",
    "    beta_samples = [beta_hat]\n",
    "    num_samples_i -= 1\n",
    "    length = 10\n",
    "    for sidx in range(num_samples_i*length):\n",
    "        # ω ~ PG(b, c) = PG(1, x*β).\n",
    "        omega_b = np.ones(num_data)\n",
    "        omega_c = X @ beta_hat\n",
    "        omega_diag = np.array(\n",
    "            [pg_dist.pgdraw(b, c) for b, c in zip(omega_b, omega_c)])\n",
    "\n",
    "        # β ~ N(m, V).\n",
    "        V = np.linalg.inv(X.T @ np.diag(omega_diag) @ X + np.linalg.inv(beta_cov))\n",
    "        m = np.dot(V, X.T @ k + np.linalg.inv(beta_cov) @ beta_mu)\n",
    "        beta_hat = np.random.multivariate_normal(m, V)\n",
    "        beta_samples.append(beta_hat)\n",
    "        \n",
    "    beta_samples = beta_samples[0:num_samples_i*length+1:length]\n",
    "    beta_samples = np.vstack(beta_samples)\n",
    "    \n",
    "    return beta_hat_return, beta_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1577be-b69b-4679-9c77-a292b1e06a13",
   "metadata": {},
   "source": [
    "### Generate prior and posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdb6e9e-0091-4db9-bd36-d5f8ef471a22",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 40\u001b[0m\n\u001b[1;32m     35\u001b[0m sample_a_y \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mbernoulli\u001b[38;5;241m.\u001b[39mrvs(sample_a_logit)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# print(data_x.shape)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# print(sample_a_y.shape)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# sample weights' posterior from polyagamma inference\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m sample_a_weights_posterior, samples_w \u001b[38;5;241m=\u001b[39m \u001b[43mgibbs_sample_polyagamma\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_a_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpg_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_prior_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mburnin_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpg_burnin_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m samples_a_weights_posterior\u001b[38;5;241m.\u001b[39mappend(sample_a_weights_posterior) \n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sidx \u001b[38;5;129;01min\u001b[39;00m idxes:\n",
      "Cell \u001b[0;32mIn [4], line 46\u001b[0m, in \u001b[0;36mgibbs_sample_polyagamma\u001b[0;34m(X, y, pg_dist, weights_prior_params, burnin_steps, num_samples_i)\u001b[0m\n\u001b[1;32m     44\u001b[0m     V \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(omega_diag) \u001b[38;5;241m@\u001b[39m X \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(beta_cov))\n\u001b[1;32m     45\u001b[0m     m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(V, X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m k \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(beta_cov) \u001b[38;5;241m@\u001b[39m beta_mu)\n\u001b[0;32m---> 46\u001b[0m     beta_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     beta_samples\u001b[38;5;241m.\u001b[39mappend(beta_hat)\n\u001b[1;32m     49\u001b[0m beta_samples \u001b[38;5;241m=\u001b[39m beta_samples[\u001b[38;5;241m0\u001b[39m:num_samples_i\u001b[38;5;241m*\u001b[39mlength\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:length]\n",
      "File \u001b[0;32mmtrand.pyx:4162\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:2265\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \n\u001b[1;32m   2264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2265\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:2375\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2373\u001b[0m yfin \u001b[38;5;241m=\u001b[39m isfinite(y)\n\u001b[1;32m   2374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(xfin) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(yfin):\n\u001b[0;32m-> 2375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwithin_tol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2377\u001b[0m     finite \u001b[38;5;241m=\u001b[39m xfin \u001b[38;5;241m&\u001b[39m yfin\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:2355\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[0;32m-> 2355\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m errstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   2356\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m less_equal(\u001b[38;5;28mabs\u001b[39m(x\u001b[38;5;241m-\u001b[39my), atol \u001b[38;5;241m+\u001b[39m rtol \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mabs\u001b[39m(y))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_ufunc_config.py:429\u001b[0m, in \u001b[0;36merrstate.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;241m=\u001b[39m call\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m--> 429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldstate \u001b[38;5;241m=\u001b[39m seterr(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Generate prior and posterior samples\n",
    "np.random.seed(0)\n",
    "\n",
    "# weights' prior distribution\n",
    "weights_prior_dist_a = stats.multivariate_normal(\n",
    "    weights_prior_params[0], weights_prior_params[1], seed=1)\n",
    "weights_prior_dist_b = stats.multivariate_normal(\n",
    "    weights_prior_params[0], weights_prior_params[1], seed=11)\n",
    "\n",
    "pg_dist = PyPolyaGamma(seed=0)\n",
    "\n",
    "samples_a_weights_prior = []\n",
    "samples_b_weights_prior = []\n",
    "samples_a_weights_posterior = []\n",
    "# samples_a_weights_posterior_params = []\n",
    "samples_a_weights_posterior_all = []\n",
    "idxes = list(np.random.randint(0, num_samples, size=5))\n",
    "idxes = [0, 4, 10, 20, 100]\n",
    "\n",
    "for sidx in range(1000):\n",
    "    num_samples_i = 0\n",
    "    if sidx in idxes:\n",
    "        num_samples_i = 10000\n",
    "        \n",
    "    # sample two set of weights' priors \n",
    "    sample_a_weights_prior = weights_prior_dist_a.rvs(1)[None,:]\n",
    "    sample_b_weights_prior = weights_prior_dist_b.rvs(1)[None,:]\n",
    "    samples_a_weights_prior.append(sample_a_weights_prior)\n",
    "    samples_b_weights_prior.append(sample_b_weights_prior)\n",
    "    # print(sample_a_weights_prior.shape)\n",
    "    # print(sample_b_weights_prior.shape)\n",
    "    \n",
    "    # generate sample y_i from theta_i in A\n",
    "    sample_a_logit = 1.0 / (1 + np.exp(-np.matmul(data_x, sample_a_weights_prior.T)))\n",
    "    sample_a_y = stats.bernoulli.rvs(sample_a_logit)\n",
    "    # print(data_x.shape)\n",
    "    # print(sample_a_y.shape)\n",
    "    \n",
    "    # sample weights' posterior from polyagamma inference\n",
    "    sample_a_weights_posterior, samples_w = gibbs_sample_polyagamma(\n",
    "        data_x, sample_a_y.squeeze(-1), \n",
    "        pg_dist, weights_prior_params, burnin_steps=pg_burnin_steps, \n",
    "        num_samples_i=num_samples_i)\n",
    "    samples_a_weights_posterior.append(sample_a_weights_posterior) \n",
    "    if sidx in idxes:\n",
    "        print(len(samples_w))\n",
    "        samples_a_weights_posterior_all.append([samples_w])\n",
    "    \n",
    "samples_a_weights_prior = np.vstack(samples_a_weights_prior)\n",
    "samples_b_weights_prior = np.vstack(samples_b_weights_prior)\n",
    "samples_a_weights_posterior = np.vstack(samples_a_weights_posterior)\n",
    "print(samples_a_weights_prior.shape)\n",
    "# print(samples_b_weights_prior)\n",
    "# print(samples_a_weights_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf71e4-31d0-44be-a32e-6957aff19005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated prior and posterior samples \n",
    "nrows = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=1, sharex=True, sharey=True, figsize=(10,10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(nrows):\n",
    "    sns.kdeplot(samples_a_weights_prior[:,0], fill=False, color=\"blue\", label=\"sample_a_prior\", ax=axes[i])\n",
    "    sns.kdeplot(samples_b_weights_prior[:,0], fill=False, color=\"green\", label=\"sample_b_prior\", ax=axes[i])\n",
    "    sns.kdeplot(samples_a_weights_posterior[:,0], fill=False, color=\"orange\", label=\"sample_a_posterior\", ax=axes[i])\n",
    "    axes[i].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4749bc-7e29-454e-8fa5-cc9df0eecd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the generated prior and posterior samples, individual features\n",
    "nrows = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=1, sharex=True, sharey=True, figsize=(10,10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "num_hist = 5\n",
    "print(samples_a_weights_posterior_all[0][0].shape)\n",
    "for i in range(nrows):\n",
    "    sns.kdeplot(samples_a_weights_prior[:,i], fill=False, color=\"blue\", label=\"samples_a_prior\", ax=axes[i])\n",
    "    sns.kdeplot(samples_b_weights_prior[:,i], fill=False, color=\"green\", label=\"samples_b_prior\", ax=axes[i])\n",
    "    sns.kdeplot(samples_a_weights_posterior[:,i], fill=False, color=\"orange\", label=\"samples_a_posterior\", ax=axes[i])\n",
    "    for j in range(num_hist):\n",
    "        samples_a_weights_posterior_j = samples_a_weights_posterior_all[j][0]\n",
    "        sns.kdeplot(samples_a_weights_posterior_j[:,i], fill=False, color=\"red\", \n",
    "                    label=f\"samples_a_posterior_{j}\", ax=axes[i])\n",
    "    axes[i].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14254641-be91-4ff3-bfd7-2204feec05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the generated prior and posterior samples \n",
    "# fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, figsize=(10,10))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# sns.kdeplot(x=samples_a_weights_prior[:,0], y=samples_a_weights_prior[:,1], n_levels=20, \n",
    "#             cmap=\"inferno\", fill=False, cbar=True, ax=axes[0])\n",
    "\n",
    "# sns.kdeplot(x=samples_b_weights_prior[:,0], y=samples_b_weights_prior[:,1], n_levels=20, \n",
    "#             cmap=\"inferno\", fill=False, cbar=True, ax=axes[1])\n",
    "\n",
    "# sns.kdeplot(x=samples_a_weights_posterior[:,0], y=samples_a_weights_posterior[:,1], n_levels=20, \n",
    "#             cmap=\"inferno\", fill=False, cbar=True, ax=axes[2])\n",
    "# axes[0].set_title(\"sample_a_prior\")\n",
    "# axes[1].set_title(\"sample_b_prior\")\n",
    "# axes[2].set_title(\"sample_a_posterior\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661a963-ba0f-4f8e-9325-69ca46350380",
   "metadata": {},
   "source": [
    "### Measure the differences between the prior and samples\n",
    "\n",
    "* Kernelized two sample test: maximum mean distance with RBF kernel\n",
    "* Wasserstein distance of two samples\n",
    "* Difference between the standard deviations (from true mean) of two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b39e8-0aec-4c04-8cb4-50925f9c16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum mean distance with RBF kernel\n",
    "mmd_rbf_prior_a_prior_b = compute_mmd_rbf(samples_a_weights_prior, samples_b_weights_prior)\n",
    "mmd_rbf_posterior_a_prior_b = compute_mmd_rbf(samples_a_weights_posterior, samples_b_weights_prior)\n",
    "print(f\"MMD between prior a and prior b: {mmd_rbf_prior_a_prior_b:0.5f}\")\n",
    "print(f\"MMD between posterior a and prior b: {mmd_rbf_posterior_a_prior_b:0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f27e9a-481a-444e-8e9e-4287a4a4a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasserstein distance with RBF kernel\n",
    "wd_prior_a_prior_b = compute_wasserstein_distance(samples_a_weights_prior, samples_b_weights_prior)\n",
    "wd_posterior_a_prior_b = compute_wasserstein_distance(samples_a_weights_posterior, samples_b_weights_prior)\n",
    "print(f\"Wasserstein distance between prior a and prior b: {wd_prior_a_prior_b:0.5f}\")\n",
    "print(f\"Wasserstein distance between posterior a and prior b: {wd_posterior_a_prior_b:0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68347512-e61c-40a3-b6dd-bb24f638fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between the standard deviations (from true mean) of two samples\n",
    "diff_std_prior_a_prior_b = compute_diff_std(samples_a_weights_prior, samples_b_weights_prior, weights_prior_params[0])\n",
    "diff_std_posterior_a_prior_b = compute_diff_std(samples_a_weights_posterior, samples_b_weights_prior, weights_prior_params[0])\n",
    "print(f\"Difference standard deviations between between prior a and prior b: {diff_std_prior_a_prior_b:0.5f}\")\n",
    "print(f\"Difference standard deviations between posterior a and prior b: {diff_std_posterior_a_prior_b:0.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
